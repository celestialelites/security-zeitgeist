# Security Zeitgeist
A list of where to find relevant security information

## Adversarial AI
- [Adversarial Learning](http://adversariallearning.com/)
- [DCGAN - Deep Convolutional Generative Adversarial Networks (TensorFlow)](https://github.com/tensorlayer/dcgan)
- [Awesome Adversarial Machine Learning (Awesome List)](https://github.com/yenchenlin/awesome-adversarial-machine-learning)
- [GAN-CLS - Generative Adversarial Text to Image Synthesis (TensorFlow](https://github.com/zsdonghao/text-to-image)
- [Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/pdf/1611.07004v1.pdf)
- [im2im - Unsupervised Image to Image Translation with Generative Adversarial Networks (TensorFlow)](https://github.com/zsdonghao/Unsup-Im2Im)
- [Metta - Information security preparedness tool to do adversarial simulation](https://github.com/uber-common/metta)
- [Information security preparedness tool to do adversarial simulation (Incident Response)](https://github.com/uber-common/metta)
- [SRGAN - Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network (TensorFlow)](https://github.com/tensorlayer/srgan)
- [Caldera - Automated adversary emulation system that performs post-compromise adversarial behavior within Windows Enterprise networks. It generates plans during operation using a planning system and a pre-configured adversary model based on the Adversarial Tactics, Techniques & Common Knowledge (ATT&CKâ„¢) project (Incident Response](https://github.com/mitre/caldera)
- [Image-to-Image Translation with Conditional Adversarial Networks  - Implementation of image to image (pix2pix) translation from the paper by isola et al (ML)](https://github.com/williamFalcon/pix2pix-keras)
- [Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling - 3D-GANs for 3D model generation and fun 3D furniture arithmetics from embeddings (think like word2vec word arithmetics with 3D furniture representations)](https://arxiv.org/pdf/1610.07584v2.pdf)

## APIs
- [Censys Internet Scan Data](https://censys.io/)
- [Google Safe Browsing](https://developers.google.com/safe-browsing/)
- [Quttera Malware API](https://quttera.com/quttera-web-malware-scanner-api) 
- [PhishTank Phishing Campaigns](https://www.phishtank.com/api_info.php) 
- [Sucuri Malware Analysis (Commercial) API](https://docs.sucuri.net/website-monitoring/scanning-api/) 
- [URLScan API](https://urlscan.io/about-api/) 
- [VirusTotal API](https://developers.virustotal.com/reference) 

## Blogs
### Adversarial AI
*  [Breaking Linear Classifiers on ImageNet](http://karpathy.github.io/2015/03/30/breaking-convnets/) , A. Karpathy et al.
*  [Breaking things is easy](http://www.cleverhans.io/security/privacy/ml/2016/12/16/breaking-things-is-easy.html) , N. Papernot & I. Goodfellow et al.
*  [Attacking Machine Learning with Adversarial Examples](https://blog.openai.com/adversarial-example-research/) , N. Papernot, I. Goodfellow, S. Huang, Y. Duan, P. Abbeel, J. Clark.
*  [Robust Adversarial Examples](https://blog.openai.com/robust-adversarial-inputs/) , Anish Athalye.
*  [A Brief Introduction to Adversarial Examples](http://people.csail.mit.edu/madry/lab/blog/adversarial/2018/07/06/adversarial_intro/) , A. Madry et al.
*  [Training Robust Classifiers (Part 1)](http://people.csail.mit.edu/madry/lab/blog/adversarial/2018/07/11/robust_optimization_part1/) , A. Madry et al.
*  [Adversarial Machine Learning Reading List](https://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html) , N. Carlini
*  [Recommendations for Evaluating Adversarial Example Defenses](https://nicholas.carlini.com/writing/2018/evaluating-adversarial-example-defenses.html) , N. Carlini


### General
- [darknet](https://www.darknet.org.uk/)
- [darkreading](https://www.darkreading.com/)
- [Google Online Security Blog](http://security.googleblog.com/)
- [lawfareblog](https://www.lawfareblog.com/taxonomy/term/5798/all)
- [Graham Cluley](https://grahamcluley.com/) 
- [Krebs on Security](https://krebsonsecurity.com/) 
- [Lawfare - Hard National Security Choices](https://www.lawfareblog.com/recent) 
- [Schneier on Security](https://www.schneier.com/) 
- [Security Affairs](https://securityaffairs.co/wordpress) 
- [The Hacker News - Cybersecurity News and Analysis](https://thehackernews.com/)
- [TaoSecurity Blog](https://taosecurity.blogspot.com/) 
- [TrendLabs Security Intelligence Blog](https://blog.trendmicro.com/trendlabs-security-intelligence) 

## Company Sites/Blogs

- [FireEye](https://www.fireeye.com/) 
- [MITRE Corporation](http://www.mitre.org/) 
- [RAND Corporation Provides Objective Research Services and â€¦](https://www.rand.org/) 
- [SANS](https://www.sans.org/) 

## Conferences
- [AWS re:Inforce 2021](https://reinforce.awsevents.com/) 
- [BlackHat USA](https://blackhat.com/) 
- [DEF CON](https://www.defcon.org/) 
- [Flocon](https://resources.sei.cmu.edu/news-events/events/flocon/)
- [Gartner Security & Risk Management Summit](https://www.gartner.com/en/conferences/na/security-risk-management-us) 
- [InfoSec World 2021](https://www.infosecworldusa.com/) 
- [RSA](https://www.rsaconference.com/usa) 
- [ShmooCon](https://shmoocon.org/) 

## Discords

- [Bug Bounty Hunters](https://disboard.org/server/785800331682381834) 
- [CSEC](https://disboard.org/server/671326654903353344) 
- [Cybersecurity Jobs/Lifestyle ðŸ’»](https://disboard.org/server/752239461793923092) 
- [Cyber Syndicates](https://disboard.org/server/678546371103424524) 
- [Hackers](https://disboard.org/server/566673537004208161) 
- [HackTheBox - Discord](https://discord.com/invite/hackthebox) 
- [Level iv Security](https://disboard.org/server/731263849990193153) 
- [NOOB SEC](https://disboard.org/server/784523699037798402) 
- [Technical Sapien](https://disboard.org/server/762184724092420116) 
- [The White Circle](https://disboard.org/server/675369276403744776) 

## Frameworks
- [Mitre Att&CkÂ®](https://attack.mitre.org/) 
- [NIST Cybersecurity Framework](https://www.nist.gov/cyberframework) 

## Mil Sites/Blogs

- [Business Insider - Defense](https://www.businessinsider.com/defense) 
- [Defence-In-Depth](https://defenceindepth.co/) 
- [Defense One - All Content](https://www.defenseone.com/) 
- [Defense.gov Explore Feed](https://www.defense.gov/explore) 
- [Janes news RSS](https://www.janes.com/) 
- [Breaking Defense](https://breakingdefense.com/) 
- [War Is Boring](https://warisboring.com/) 
- [War on the Rocks](http://warontherocks.com/) 
- [Modern War Institute](https://mwi.usma.edu/) 

## Newsletters

- [Speaking Security](https://stephensemler.substack.com/) 
- [This Week in Security w/ Zach Whittaker](https://us18.campaign-archive.com/home/?u=e1ad6038c994abec17dafb116&id=a2457dc8ad)

## OSS Security Projects
- [Apache Metron Big Data Security](http://metron.apache.org/) 
- [Awesome-Hacking List](https://github.com/Hack-with-Github/Awesome-Hacking) 
- [Awesome-Web-Security List](https://github.com/qazbnm456/awesome-web-security) 

### Adversarial OSS Projects

- [Alibi Detect Python library]([GitHub - SeldonIO/alibi-detect: Algorithms for outlier and adversarial instance detection, concept drift and metrics.](https://github.com/SeldonIO/alibi-detect)) - outlier, adversarial and drift detection. The package aims to cover both online and offline detectors for tabular data, text, images and time series. The outlier detection methods should allow the user to identify global, contextual and collective outliers.
- [DCGAN - Deep Convolutional Generative Adversarial Networks (TensorFlow)](https://github.com/tensorlayer/dcgan)
- [GAN-CLS - Generative Adversarial Text to Image Synthesis (TensorFlow](https://github.com/zsdonghao/text-to-image)
- [im2im -  Unsupervised Image to Image Translation with Generative Adversarial Networks (TensorFlow)](https://github.com/zsdonghao/Unsup-Im2Im)
- [Metta - Information security preparedness tool to do adversarial simulation](https://github.com/uber-common/metta)
- [Information security preparedness tool to do adversarial simulation (Incident Response)](https://github.com/uber-common/metta)
- [SRGAN - Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network (TensorFlow)](https://github.com/tensorlayer/srgan)
- [Caldera -  Automated adversary emulation system that performs post-compromise adversarial behavior within Windows Enterprise networks. It generates plans during operation using a planning system and a pre-configured adversary model based on the Adversarial Tactics, Techniques & Common Knowledge (ATT&CKâ„¢) project (Incident Response](https://github.com/mitre/caldera)
- [Image-to-Image Translation with Conditional Adversarial Networks  - Implementation of image to image (pix2pix) translation from the paper by isola et al (ML)](https://github.com/williamFalcon/pix2pix-keras)


## Other Awesome Lists
* [Application Security](https://github.com/paragonie/awesome-appsec#readme) 
* [Security](https://github.com/sbilly/awesome-security#readme) 
* [CTF](https://github.com/apsdehal/awesome-ctf#readme)  - Capture The Flag.
* [Malware Analysis](https://github.com/rshipp/awesome-malware-analysis#readme) 
* [Android Security](https://github.com/ashishb/android-security-awesome#readme) 
* [Hacking](https://github.com/carpedm20/awesome-hacking#readme) 
* [Honeypots](https://github.com/paralax/awesome-honeypots#readme)  - Deception trap, designed to entice an attacker into attempting to compromise the information systems in an organization.
* [Incident Response](https://github.com/meirwah/awesome-incident-response#readme) 
* [Vehicle Security and Car Hacking](https://github.com/jaredthecoder/awesome-vehicle-security#readme) 
* [Web Security](https://github.com/qazbnm456/awesome-web-security#readme)  - Security of web apps & services.
* [Lockpicking](https://github.com/fabacab/awesome-lockpicking#readme)  - The art of unlocking a lock by manipulating its components without the key.
* [Cybersecurity Blue Team](https://github.com/fabacab/awesome-cybersecurity-blueteam#readme)  - Groups of individuals who identify security flaws in information technology systems.
* [Fuzzing](https://github.com/cpuu/awesome-fuzzing#readme)  - Automated software testing technique that involves feeding pseudo-randomly generated input data.
* [Embedded and IoT Security](https://github.com/fkie-cad/awesome-embedded-and-iot-security#readme) 
* [GDPR](https://github.com/bakke92/awesome-gdpr#readme)  - Regulation on data protection and privacy for all individuals within EU.
* [DevSecOps](https://github.com/TaptuIT/awesome-devsecops#readme)  - Integration of security practices into  [DevOps](https://en.wikipedia.org/wiki/DevOps) .

## Papers

### Adversarial

**General**
*  [Intriguing properties of neural networks](https://arxiv.org/abs/1312.6199) , C. Szegedy et al., arxiv 2014
*  [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572) , I. Goodfellow et al., ICLR 2015
*  [Motivating the Rules of the Game for Adversarial Example Research](https://arxiv.org/abs/1807.06732) , J. Gilmer et al., arxiv 2018
*  [Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning](https://arxiv.org/abs/1712.03141) , B. Biggio, Pattern Recognition 2018
**Attack**
**Image Classification**
*  [DeepFool: a simple and accurate method to fool deep neural networks](https://arxiv.org/abs/1511.04599) , S. Moosavi-Dezfooli et al., CVPR 2016
*  [The Limitations of Deep Learning in Adversarial Settings](https://arxiv.org/abs/1511.07528) , N. Papernot et al., ESSP 2016
*  [Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples](https://arxiv.org/abs/1605.07277) , N. Papernot et al., arxiv 2016
* [Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/pdf/1611.07004v1.pdf)
*  [Adversarial Examples In The Physical World](https://arxiv.org/pdf/1607.02533v3.pdf) , A. Kurakin et al., ICLR workshop 2017
*  [Delving into Transferable Adversarial Examples and Black-box Attacks](https://arxiv.org/abs/1611.02770)  Liu et al., ICLR 2017
*  [Towards Evaluating the Robustness of Neural Networks](https://arxiv.org/abs/1608.04644)  N. Carlini et al., SSP 2017
*  [Practical Black-Box Attacks against Deep Learning Systems using Adversarial Examples](https://arxiv.org/abs/1602.02697) , N. Papernot et al., Asia CCS 2017
*  [Privacy and machine learning: two unexpected allies?](http://www.cleverhans.io/privacy/2018/04/29/privacy-and-machine-learning.html) , I. Goodfellow et al.
**Reinforcement Learning**
*  [Adversarial attacks on neural network policies](https://arxiv.org/abs/1702.02284) , S. Huang et al, ICLR workshop 2017
*  [Tactics of Adversarial Attacks on Deep Reinforcement Learning Agents](https://arxiv.org/abs/1703.06748) , Y. Lin et al, IJCAI 2017
*  [Delving into adversarial attacks on deep policies](https://arxiv.org/abs/1705.06452) , J. Kos et al., ICLR workshop 2017
**Segmentation & Object Detection**
*  [Adversarial Examples for Semantic Segmentation and Object Detection](https://arxiv.org/pdf/1703.08603.pdf) , C. Xie, ICCV 2017
* [Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling -  3D-GANs for 3D model generation and fun 3D furniture arithmetics from embeddings (think like word2vec word arithmetics with 3D furniture representations)](https://arxiv.org/pdf/1610.07584v2.pdf)
**VAE-GAN**
*  [Adversarial examples for generative models](https://arxiv.org/abs/1702.06832) , J. Kos et al. arxiv 2017
**Speech Recognition**
*  [Audio Adversarial Examples: Targeted Attacks on Speech-to-Text](https://arxiv.org/abs/1801.01944) , N. Carlini et al., arxiv 2018
**Questiona Answering System**
*  [Adversarial Examples for Evaluating Reading Comprehension Systems](https://arxiv.org/abs/1707.07328) , R. Jia et al., EMNLP 2017
**Defence**
**Adversarial Training**
*  [Adversarial Machine Learning At Scale](https://arxiv.org/pdf/1611.01236.pdf) , A. Kurakin et al., ICLR 2017
*  [Ensemble Adversarial Training: Attacks and Defenses](https://arxiv.org/abs/1705.07204) , F. TramÃ¨r et al., arxiv 2017
**Defensive Distillation**
*  [Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks](https://arxiv.org/pdf/1511.04508.pdf) , N. Papernot et al., SSP 2016
*  [Extending Defensive Distillation](https://arxiv.org/abs/1705.05264) , N. Papernot et al., arxiv 2017
**Generative Model**
*  [PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples](https://arxiv.org/abs/1710.10766) , Y. Song et al., ICLR 2018
*  [Detecting Adversarial Attacks on Neural Network Policies with Visual Foresight](https://arxiv.org/abs/1710.00814) , Y. Lin et al., NIPS workshop 2017
**Regularization**
*  [Distributional Smoothing with Virtual Adversarial Training](https://arxiv.org/abs/1507.00677) , T. Miyato et al., ICLR 2016
*  [Adversarial Training Methods for Semi-Supervised Text Classification](https://arxiv.org/abs/1605.07725) , T. Miyato et al., ICLR 2017
**Others**
*  [Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images](https://arxiv.org/abs/1412.1897) , A. Nguyen et al., CVPR 2015

## Podcasts
- [Adversarial Learning](http://adversariallearning.com/)
- [Brakeing Security](https://brakeingsecurity.com/)
- [Darknet Diaries](https://darknetdiaries.com/)
- [Hidden Forces](https://hiddenforces.io/)
- [Irregular Warfare Podcast](https://mwi.usma.edu/competing-for-influence-operations-in-the-information-environment/) 
- [Malicious Life](https://malicious.life/)
- [Purple Squad Security](https://purplesquadsec.com/)
- [Rational Security](https://www.lawfareblog.com/)
- [SEI Cyber Talks](http://cmu-sei-cybertalks.seimedia.libsynpro.com/)

## Slacks

- [MITRE ATT&CK](https://mitreattack.slack.com)
- [Pittsburgh InfoSec](https://pittsec.slack.com)
- [TrustedSec Public](https://trustedsec.slack.com)

## Talks

*  [Do Statistical Models Understand the World?](https://www.youtube.com/watch?v=Pq4A2mPCB0Y) , I. Goodfellow, 2015
*  [Classifiers under Attack](https://www.usenix.org/conference/enigma2017/conference-program/presentation/evans) , David Evans, 2017
*  [Adversarial Examples in Machine Learning](https://www.usenix.org/conference/enigma2017/conference-program/presentation/papernot) , Nicolas Papernot, 2017
*  [Poisoning Behavioral Malware Clustering](http://pralab.diee.unica.it/en/node/1121) , Biggio. B, Rieck. K, Ariu. D, Wressnegger. C, Corona. I. Giacinto, G. Roli. F, 2014
*  [Is Data Clustering in Adversarial Settings Secure?](http://pralab.diee.unica.it/en/node/955) , BBiggio. B, Pillai. I, Rota BulÃ². S, Ariu. D, Pelillo. M, Roli. F, 2015
*  [Poisoning complete-linkage hierarchical clustering](http://pralab.diee.unica.it/en/node/1089) , Biggio. B, Rota BulÃ². S, Pillai. I, Mura. M, Zemene Mequanint. E, Pelillo. M, Roli. F, 2014
*  [Is Feature Selection Secure against Training Data Poisoning?](https://pralab.diee.unica.it/en/node/1191) , Xiao. H, Biggio. B, Brown. G, Fumera. G, Eckert. C, Roli. F, 2015
*  [Adversarial Feature Selection Against Evasion Attacks](https://pralab.diee.unica.it/en/node/1188) , Zhang. F, Chan. PPK, Biggio. B, Yeung. DS, Roli. F, 2016


## Twitter Lists
(search for these via `site:twitter.com lists/infosec`)

- [Dustinâ€™s Infosec](https://twitter.com/i/lists/1326994585319567361)
- [Keith Crawfordâ€™s Cybersecurity](https://twitter.com/i/lists/13885)
- [Parisa Tabrizâ€™s Security](https://twitter.com/i/lists/61139416)
- [Swift on Securityâ€™s News-InfoSec/DFIR](https://twitter.com/i/lists/181682922)
